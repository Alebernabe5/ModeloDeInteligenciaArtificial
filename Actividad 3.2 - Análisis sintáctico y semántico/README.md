# Actividad 3.2: An√°lisis Sint√°ctico y Sem√°ntico con spaCy üöÄ

Este proyecto aplica t√©cnicas avanzadas de **Procesamiento de Lenguaje Natural (NLP)** para analizar las opiniones de los usuarios sobre un producto real. El objetivo es extraer informaci√≥n valiosa (sentimiento, entidades y temas) de forma automatizada.

## üì¶ Art√≠culo Seleccionado
**Producto:** [Amazon Kindle (2024)](https://www.amazon.es/kindle-2024/dp/B0CP32JG8B)
> "El Kindle m√°s ligero y compacto, con pantalla sin reflejos, pasos de p√°gina m√°s fluidos y luz frontal ajustable."

---

üß† Metodolog√≠a y Arquitectura del Pipeline
A diferencia de un an√°lisis b√°sico, este proyecto utiliza un Pipeline H√≠brido. Se ha modificado el flujo est√°ndar de spaCy para integrar reglas l√≥gicas fijas con modelos de aprendizaje estad√≠stico:

Capa de Reglas (Heur√≠stica): Mediante el EntityRuler, aseguramos que t√©rminos espec√≠ficos de Amazon no sean mal clasificados por la IA.

Capa Estad√≠stica: El modelo es_core_news_lg realiza el etiquetado morfosint√°ctico bas√°ndose en el contexto.

Capa de Extensi√≥n: Se a√±ade un "bus de datos" adicional (spacy-textblob) que viaja por todo el documento calculando la carga emocional de cada palabra.

## üîç An√°lisis del C√≥digo Paso a Paso
1. Preparaci√≥n del Entorno e Importaciones
Se cargan las herramientas de spaCy (displacy, EntityRuler), random para la selecci√≥n de muestras y spacy-textblob para el sentimiento.

Se carga el modelo lg, fundamental para el paso de similitud sem√°ntica gracias a sus Word Vectors de 300 dimensiones.

2. Carga y Procesamiento de Datos
Se gestiona la lectura del archivo comentariosKindle.txt con codificaci√≥n utf-8.

doc = nlp(text): Se genera el objeto Doc, transformando el texto plano en una estructura de datos ling√º√≠stica explotable.

Limpieza (Preprocessing): Funci√≥n que devuelve los lemas omitiendo stopwords y puntuaci√≥n.

3. Configuraci√≥n del Pipeline (Reto)
Se inyecta el EntityRuler antes del NER autom√°tico para que las palabras personalizadas (como Kindle o Calibre) tengan "personalidad" y prioridad.

Se inyecta el componente de sentimiento para que est√© disponible en todo el pipeline.

4. Salidas NER y Sentimiento
Entidades: Iteraci√≥n por nombres propios detectados, traduciendo etiquetas t√©cnicas a lenguaje humano.

Score de Sentimiento: Se extrae un valor num√©rico (entre -1 y 1) mediante doc._.blob.polarity. Se aplica l√≥gica para categorizar el resultado como Positivo, Negativo o Neutro.

5. Descubrimiento de T√≥picos
Estrategia A (Frecuencia): Busca palabras con la etiqueta NOUN (sustantivos), identificando los temas m√°s repetidos.

Estrategia B (Sem√°ntica): Se utiliza doc.similarity() para comparar la posici√≥n matem√°tica (vector) de los comentarios con categor√≠as candidatas (Tecnolog√≠a, Deporte, etc.).

6. An√°lisis Sint√°ctico Visual
phrase_ejem: Selecci√≥n de una oraci√≥n al azar del corpus.

POS & DEP: Identificaci√≥n de categor√≠as gramaticales y relaciones de dependencia.

Identificaci√≥n de Verbos: Localizaci√≥n visual del n√∫cleo de la oraci√≥n (ROOT) y auxiliares.

displacy.serve: Lanzamiento de un servidor local para visualizar el √°rbol de dependencias.

## üìä Interpretaci√≥n para el Informe Ejecutivo
An√°lisis Sint√°ctico: Permite extraer qu√© acciones realizan los usuarios con el producto (ej: "leer", "cargar").

An√°lisis de T√≥picos: Capacidad de categorizar el texto por "intenci√≥n" incluso si no se mencionan palabras t√©cnicas.

Polaridad: Un score cercano a 1.0 indica satisfacci√≥n total, mientras que valores inferiores a 0 activan alertas de posibles quejas t√©cnicas.

## üõ†Ô∏è Requisitos e Instalaci√≥n

Para ejecutar este script, es necesario tener instalado Python y las siguientes librer√≠as:

```bash
# Instalaci√≥n de librer√≠as
pip install spacy spacytextblob pandas

# Descarga del modelo de lenguaje en espa√±ol (Large)
python -m spacy download es_core_news_lg

