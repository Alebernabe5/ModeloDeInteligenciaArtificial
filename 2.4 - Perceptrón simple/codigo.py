import pandas as pd
import numpy as np

# ==========================================
# PASO 1: SELECCIÃ“N Y PREPARACIÃ“N DEL DATO
# ==========================================
ruta = 'data.csv'  # AsegÃºrate de que el archivo se llame asÃ­ en tu carpeta

try:
    # Carga de datos con detecciÃ³n de separador
    df = pd.read_csv(ruta, sep=None, engine='python')
    print(f"âœ… Archivo cargado. Filas originales: {len(df)}")

    # 1.1 Limpieza: Eliminar columna de ID y la columna vacÃ­a 'Unnamed: 32'
    # Esto es crucial para que dropna() no elimine todos los datos
    df = df.drop(columns=['id', 'Unnamed: 32'], errors='ignore')

    # 1.2 CodificaciÃ³n: Convertir 'diagnosis' (M/B) a numÃ©rico (1/0)
    if 'diagnosis' in df.columns:
        df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})

    # 1.3 Eliminar filas con valores nulos restantes
    df_clean = df.dropna()
    print(f"âœ… Datos tras limpieza: {len(df_clean)} filas.")

    # 1.4 SelecciÃ³n de variables independientes (Features) y dependiente (Target)
    # Seleccionamos 3 variables fÃ­sicas representativas
    features = ['radius_mean', 'texture_mean', 'perimeter_mean']
    X = df_clean[features].values.astype(float)
    y = df_clean['diagnosis'].values

    # 1.5 NormalizaciÃ³n (Z-Score): Escalar los datos para que el PerceptrÃ³n converja
    X_std = np.copy(X)
    for i in range(X.shape[1]):
        X_std[:, i] = (X[:, i] - X[:, i].mean()) / X[:, i].std()
    
    print("âœ… NormalizaciÃ³n completada.")

except Exception as e:
    print(f"âŒ Error en la preparaciÃ³n de datos: {e}")
    X_std, y = None, None

# ==========================================
# PASO 2: DESARROLLO DEL NÃšCLEO (CLASE)
# ==========================================
class Perceptron:
    def __init__(self, eta=0.01, n_iter=50):
        self.eta = eta          # Tasa de aprendizaje
        self.n_iter = n_iter    # Ã‰pocas (iteraciones)

    def fit(self, X, y):
        """Ajusta los pesos entrenando con los datos X e y"""
        # Inicializamos pesos: [bias, w1, w2, w3]
        self.w_ = np.zeros(1 + X.shape[1])
        self.errors_ = []

        for _ in range(self.n_iter):
            errors = 0
            for xi, target in zip(X, y):
                # Regla de actualizaciÃ³n del PerceptrÃ³n
                update = self.eta * (target - self.predict(xi))
                self.w_[1:] += update * xi
                self.w_[0] += update  # ActualizaciÃ³n del sesgo (bias)
                errors += int(update != 0.0)
            self.errors_.append(errors)
        return self

    def net_input(self, X):
        """Calcula el valor neto (z) antes de la activaciÃ³n"""
        return np.dot(X, self.w_[1:]) + self.w_[0]

    def predict(self, X):
        """FunciÃ³n de activaciÃ³n: EscalÃ³n unitario (Heaviside)"""
        return np.where(self.net_input(X) >= 0.0, 1, 0)

# # ==========================================
# PASO 3: ENTRENAMIENTO Y VALIDACIÃ“N
# ==========================================
if X_std is not None:
    # 3.1 DivisiÃ³n manual (Split) 80% Entrenamiento / 20% Test
    limit = int(len(X_std) * 0.8)
    X_train, X_test = X_std[:limit], X_std[limit:]
    y_train, y_test = y[:limit], y[limit:]

    # 3.2 Instanciar y Entrenar
    # eta: tasa de aprendizaje, n_iter: nÃºmero de Ã©pocas
    modelo = Perceptron(eta=0.01, n_iter=50)
    modelo.fit(X_train, y_train)
    print("âœ… Entrenamiento finalizado.")

    # 3.3 EvaluaciÃ³n del rendimiento en ENTRENAMIENTO
    preds_train = modelo.predict(X_train)
    accuracy_train = np.mean(preds_train == y_train) * 100

    # 3.4 EvaluaciÃ³n del rendimiento en TEST
    preds_test = modelo.predict(X_test)
    accuracy_test = np.mean(preds_test == y_test) * 100
    
    # 3.5 Salida por consola detallada
    print("-" * 40)
    print("ESTADÃSTICAS DEL MODELO:")
    print(f"ğŸ“Š PrecisiÃ³n en Entrenamiento: {accuracy_train:.2f}%")
    print(f"ğŸ¯ PrecisiÃ³n en Test (ValidaciÃ³n): {accuracy_test:.2f}%")
    print("-" * 40)
    print(f"Pesos finales (w): {modelo.w_[1:]}")
    print(f"Sesgo final (bias): {modelo.w_[0]}")
    print("-" * 40)

    # Opcional: Ver si el error llegÃ³ a cero
    if modelo.errors_[-1] == 0:
        print("ğŸ’¡ El modelo convergiÃ³ perfectamente (error 0).")
    else:
        print(f"ğŸ’¡ El modelo terminÃ³ con {modelo.errors_[-1]} errores en la Ãºltima Ã©poca.")